{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["uation_one"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import\u00c2\u00a0json \n", "import\u00c2\u00a0requests \n", "from\u00c2\u00a0bs4\u00c2\u00a0import\u00c2\u00a0BeautifulSoup \n", "  \n", " url1\u00c2\u00a0=\u00c2\u00a0\"https://www.bu.edu/president/boston-university-facts-stats/\" \n", " response1\u00c2\u00a0=\u00c2\u00a0requests.get(url1) \n", " content1\u00c2\u00a0=\u00c2\u00a0response1.content \n", " soup1\u00c2\u00a0=\u00c2\u00a0BeautifulSoup(content1,\u00c2\u00a0'html.parser') \n", " tables\u00c2\u00a0=\u00c2\u00a0soup1.findAll('div',\u00c2\u00a0{\"class\":\u00c2\u00a0\"facts-wrapper\"}) \n", "  \n", " list_of_tables\u00c2\u00a0=\u00c2\u00a0[] \n", "  \n", " for\u00c2\u00a0i\u00c2\u00a0in\u00c2\u00a0tables: \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0keys\u00c2\u00a0=\u00c2\u00a0[] \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0values\u00c2\u00a0=\u00c2\u00a0[] \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0temp_dict\u00c2\u00a0=\u00c2\u00a0{} \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0i\u00c2\u00a0=\u00c2\u00a0str(i) \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0category\u00c2\u00a0=\u00c2\u00a0i[i.find('<h5>')\u00c2\u00a0+\u00c2\u00a04:\u00c2\u00a0i.find('</h5>')] \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0temp_dict['Category']\u00c2\u00a0=\u00c2\u00a0category \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0all_key_start_indexes\u00c2\u00a0=\u00c2\u00a0[x+7\u00c2\u00a0for\u00c2\u00a0x\u00c2\u00a0in\u00c2\u00a0range(len(i))\u00c2\u00a0if\u00c2\u00a0i.startswith('\"text\">',\u00c2\u00a0x)] \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0all_key_end_indexes\u00c2\u00a0=\u00c2\u00a0[x\u00c2\u00a0for\u00c2\u00a0x\u00c2\u00a0in\u00c2\u00a0range(len(i))\u00c2\u00a0if\u00c2\u00a0i.startswith('</p>',\u00c2\u00a0x)] \n", "  \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0for\u00c2\u00a0l\u00c2\u00a0in\u00c2\u00a0range(len(all_key_start_indexes)): \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0keys.append(i[all_key_start_indexes[l]:all_key_end_indexes[l]]) \n", "  \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0all_values_start_indexes\u00c2\u00a0=\u00c2\u00a0[] \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0for\u00c2\u00a0v\u00c2\u00a0in\u00c2\u00a0range(len(i)): \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0if\u00c2\u00a0i.startswith('value\">',\u00c2\u00a0v): \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0all_values_start_indexes.append(v+7) \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0if\u00c2\u00a0i.startswith('value-text\">',\u00c2\u00a0v): \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0all_values_start_indexes.append(v+12) \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0all_values_end_indexes\u00c2\u00a0=\u00c2\u00a0[x\u00c2\u00a0for\u00c2\u00a0x\u00c2\u00a0in\u00c2\u00a0range(len(i))\u00c2\u00a0if\u00c2\u00a0i.startswith('</span>',\u00c2\u00a0x)] \n", "  \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0for\u00c2\u00a0m\u00c2\u00a0in\u00c2\u00a0range(len(all_values_end_indexes)): \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0values.append(i[all_values_start_indexes[m]:all_values_end_indexes[m]]) \n", "  \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0for\u00c2\u00a0r\u00c2\u00a0in\u00c2\u00a0range(len(keys)): \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0temp_dict[keys[r]]\u00c2\u00a0=\u00c2\u00a0values[r] \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0list_of_tables.append(temp_dict) \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0 \n", " #\u00c2\u00a0pprint(list_of_tables) \n", " with\u00c2\u00a0open(r\"22_Day_Web_scraping\\scrapped_exercise_1.json\",\u00c2\u00a0'w')\u00c2\u00a0as\u00c2\u00a0fp: \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0json.dump(list_of_tables,\u00c2\u00a0fp)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["uation_two"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  import\u00c2\u00a0requests \n", " import\u00c2\u00a0pandas\u00c2\u00a0as\u00c2\u00a0pd \n", " import\u00c2\u00a0csv \n", " import\u00c2\u00a0json \n", " from\u00c2\u00a0os\u00c2\u00a0import\u00c2\u00a0remove \n", "  \n", " url\u00c2\u00a0=\u00c2\u00a0'https://archive.ics.uci.edu/ml/datasets.php' \n", " df\u00c2\u00a0=\u00c2\u00a0pd.read_html(requests.get(url).content)[5] \n", "df.to_csv('22_Day_Web_scraping\\scrapped_data.csv',\u00c2\u00a0header=None) \n", " def\u00c2\u00a0make_json(csvFilePath,\u00c2\u00a0jsonFilePath): \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0data\u00c2\u00a0=\u00c2\u00a0{} \n", "  \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0with\u00c2\u00a0open(csvFilePath,\u00c2\u00a0encoding='utf-8')\u00c2\u00a0as\u00c2\u00a0csvf: \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0csvReader\u00c2\u00a0=\u00c2\u00a0csv.DictReader(csvf) \n", "  \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0for\u00c2\u00a0rows\u00c2\u00a0in\u00c2\u00a0csvReader: \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0key\u00c2\u00a0=\u00c2\u00a0rows['Name'] \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0data[key]\u00c2\u00a0=\u00c2\u00a0rows \n", "  \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0with\u00c2\u00a0open(jsonFilePath,\u00c2\u00a0'w',\u00c2\u00a0encoding='utf-8')\u00c2\u00a0as\u00c2\u00a0jsonf: \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0jsonf.write(json.dumps(data,\u00c2\u00a0indent=4))  csvFilePath\u00c2\u00a0=\u00c2\u00a0r'22_Day_Web_scraping\\scrapped_data.csv' \n", " jsonFilePath\u00c2\u00a0=\u00c2\u00a0r'22_Day_Web_scraping\\scrapped_datasets.json' \n", " make_json(csvFilePath,\u00c2\u00a0jsonFilePath) \n", " remove(r'22_Day_Web_scraping\\scrapped_data.csv')\n", " \n", " #quation_three\n", " url\u00c2\u00a0=\u00c2\u00a0'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States' \n", " df\u00c2\u00a0=\u00c2\u00a0pd.read_html(requests.get(url).content) \n", " df\u00c2\u00a0=\u00c2\u00a0df[1] \n", " df\u00c2\u00a0=\u00c2\u00a0df.iloc[:-1] \n", " nan_value\u00c2\u00a0=\u00c2\u00a0float(\"NaN\") \n", " df.replace(\"\",\u00c2\u00a0nan_value,\u00c2\u00a0inplace=True) \n", " df.dropna(how='all',\u00c2\u00a0axis=1,\u00c2\u00a0inplace=True) \n", " df.to_csv('22_Day_Web_scraping\\presidents.csv') \n", " def\u00c2\u00a0make_json(csvFilePath,\u00c2\u00a0jsonFilePath): \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0data\u00c2\u00a0=\u00c2\u00a0{} \n", "  \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0with\u00c2\u00a0open(csvFilePath,\u00c2\u00a0encoding='utf-8')\u00c2\u00a0as\u00c2\u00a0csvf: \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0csvReader\u00c2\u00a0=\u00c2\u00a0csv.DictReader(csvf) \n", "  \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0for\u00c2\u00a0rows\u00c2\u00a0in\u00c2\u00a0csvReader: \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0key\u00c2\u00a0=\u00c2\u00a0rows[''] \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0data[key]\u00c2\u00a0=\u00c2\u00a0rows \n", "  \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0with\u00c2\u00a0open(jsonFilePath,\u00c2\u00a0'w',\u00c2\u00a0encoding='utf-8')\u00c2\u00a0as\u00c2\u00a0jsonf: \n", " \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0jsonf.write(json.dumps(data,\u00c2\u00a0indent=4,\u00c2\u00a0ensure_ascii=False))  csvFilePath\u00c2\u00a0=\u00c2\u00a0r'22_Day_Web_scraping\\presidents.csv' \n", " jsonFilePath\u00c2\u00a0=\u00c2\u00a0r'22_Day_Web_scraping\\presidents.json' \n", " make_json(csvFilePath,\u00c2\u00a0jsonFilePath) \n", " remove(r'22_Day_Web_scraping\\presidents.csv')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}